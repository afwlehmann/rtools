% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/information.R
\name{entropy}
\alias{entropy}
\title{Entropy of a random variable.}
\usage{
entropy(x, breaks, base = exp(1))
}
\arguments{
\item{x}{a vector or a factor}

\item{breaks}{see \code{\link{cut}}}

\item{base}{the base of the logarithm (2 = bits, exp(1) = nats, etc.)}
}
\value{
the discrete entropy of X
}
\description{
\deqn{H(X) = -\sum_x p(x) \cdot \log p(x)}
}
\details{
For numeric vectors, a histogram of the values in \code{x} will be computed
after quantization of \code{x} according to the given \code{breaks}.

For factors, a histogram will be computed according to the relative
frequencies of the factor levels.
}

